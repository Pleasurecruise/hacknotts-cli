/**
 * AI Service - ç®¡ç† AI Provider åˆå§‹åŒ–å’Œå¯¹è¯
 * ä½¿ç”¨ @cherrystudio/ai-core è¿›è¡Œ AI äº¤äº’
 */
import { config } from 'dotenv'
import { createExecutor, createPromptToolUsePlugin } from '@cherrystudio/ai-core'
import { createAndRegisterProvider } from '@cherrystudio/ai-core/provider'
import type { ProviderId } from '@cherrystudio/ai-core/provider'
import { createMcpPlugin } from 'toolkit'

// åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆä» .env æ–‡ä»¶æˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡ï¼‰
config({ path: '.env' })

/**
 * AI Provider é…ç½®æ¥å£
 */
export interface AIConfig {
  providerId: ProviderId
  model: string
  apiKey: string
  baseURL?: string
  useCompatibleMode?: boolean
}

/**
 * æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨ OpenAI Compatible æ¨¡å¼
 */
function shouldUseCompatibleMode(baseURL?: string): boolean {
  if (!baseURL) return false

  // å®˜æ–¹ OpenAI API ä¸éœ€è¦ compatible æ¨¡å¼
  if (baseURL.includes('api.openai.com')) return false

  // å…¶ä»–è‡ªå®šä¹‰ URL éƒ½ä½¿ç”¨ compatible æ¨¡å¼
  return true
}

/**
 * ä»ç¯å¢ƒå˜é‡è·å–æ‰€æœ‰é…ç½®çš„ Provider
 * @returns æ‰€æœ‰é…ç½®çš„ Provider æ•°ç»„
 */
export function getAllAIConfigsFromEnv(): AIConfig[] {
  const configs: AIConfig[] = []

  // æ£€æŸ¥ OpenAI é…ç½®
  const openaiApiKey = process.env.OPENAI_API_KEY
  if (openaiApiKey) {
    const baseURL = process.env.OPENAI_BASE_URL
    const model = process.env.OPENAI_MODEL || 'gpt-4o-mini'
    const useCompatibleMode = shouldUseCompatibleMode(baseURL)

    configs.push({
      providerId: useCompatibleMode ? ('openai-compatible' as ProviderId) : ('openai' as ProviderId),
      model,
      apiKey: openaiApiKey,
      baseURL,
      useCompatibleMode
    })
  }

  // æ£€æŸ¥ Anthropic é…ç½®
  const anthropicApiKey = process.env.ANTHROPIC_API_KEY
  if (anthropicApiKey) {
    configs.push({
      providerId: 'anthropic' as ProviderId,
      model: process.env.ANTHROPIC_MODEL || 'claude-3-5-sonnet-20241022',
      apiKey: anthropicApiKey,
      baseURL: process.env.ANTHROPIC_BASE_URL
    })
  }

  // æ£€æŸ¥ DeepSeek é…ç½®
  const deepseekApiKey = process.env.DEEPSEEK_API_KEY
  if (deepseekApiKey) {
    configs.push({
      providerId: 'deepseek' as ProviderId,
      model: process.env.DEEPSEEK_MODEL || 'deepseek-chat',
      apiKey: deepseekApiKey,
      baseURL: process.env.DEEPSEEK_BASE_URL
    })
  }

  // æ£€æŸ¥ Google é…ç½®
  const googleApiKey = process.env.GOOGLE_API_KEY
  if (googleApiKey) {
    configs.push({
      providerId: 'google' as ProviderId,
      model: process.env.GOOGLE_MODEL || 'gemini-1.5-flash',
      apiKey: googleApiKey,
      baseURL: process.env.GOOGLE_BASE_URL
    })
  }

  return configs
}

/**
 * ä»ç¯å¢ƒå˜é‡è·å– Provider é…ç½®ï¼ˆè¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ï¼‰
 * @deprecated å»ºè®®ä½¿ç”¨ getAllAIConfigsFromEnv() å’Œ initializeAllProviders()
 */
export function getAIConfigFromEnv(): AIConfig | null {
  const configs = getAllAIConfigsFromEnv()
  return configs.length > 0 ? configs[0] : null
}

/**
 * åˆå§‹åŒ–æ‰€æœ‰é…ç½®çš„ AI Providers
 * @returns æˆåŠŸåˆå§‹åŒ–çš„é…ç½®æ•°ç»„
 */
export async function initializeAllProviders(): Promise<AIConfig[]> {
  const allConfigs = getAllAIConfigsFromEnv()

  if (allConfigs.length === 0) {
    console.error('âŒ No valid AI provider configuration found in environment variables.')
    console.error('Please set one of the following in your .env file or system environment:')
    console.error('  - OPENAI_API_KEY')
    console.error('  - ANTHROPIC_API_KEY')
    console.error('  - DEEPSEEK_API_KEY')
    console.error('  - GOOGLE_API_KEY')
    return []
  }

  const initialized: AIConfig[] = []

  console.log(`ğŸ”„ Initializing ${allConfigs.length} provider(s)...`)

  for (const aiConfig of allConfigs) {
    try {
      // å‡†å¤‡ provider é€‰é¡¹
      const providerOptions: any = {
        apiKey: aiConfig.apiKey
      }

      // å¦‚æœæœ‰è‡ªå®šä¹‰ baseURLï¼Œæ·»åŠ åˆ°é€‰é¡¹ä¸­
      if (aiConfig.baseURL) {
        providerOptions.baseURL = aiConfig.baseURL
      }

      // åˆ›å»ºå¹¶æ³¨å†Œ Provider
      const success = await createAndRegisterProvider(aiConfig.providerId, providerOptions)

      if (!success) {
        console.error(`âŒ Failed to register ${aiConfig.providerId} provider`)
        continue
      }

      const displayName = aiConfig.useCompatibleMode
        ? `${aiConfig.providerId} (${aiConfig.baseURL})`
        : aiConfig.providerId

      console.log(`âœ… Successfully initialized ${displayName} provider`)
      console.log(`   Model: ${aiConfig.model}`)
      if (aiConfig.useCompatibleMode) {
        console.log(`   Mode: OpenAI-Compatible`)
      }

      initialized.push(aiConfig)
    } catch (error) {
      console.error(`âŒ Failed to initialize ${aiConfig.providerId} provider:`, error)
    }
  }

  if (initialized.length > 0) {
    console.log(`\nğŸ‰ Successfully initialized ${initialized.length} provider(s)`)
  }

  return initialized
}

/**
 * åˆå§‹åŒ– AI Providerï¼ˆè¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸåˆå§‹åŒ–çš„ï¼‰
 * @deprecated å»ºè®®ä½¿ç”¨ initializeAllProviders()
 */
export async function initializeAIProvider(): Promise<AIConfig | null> {
  const initialized = await initializeAllProviders()
  return initialized.length > 0 ? initialized[0] : null
}

/**
 * åˆ›å»º AI èŠå¤©æµ
 * ä½¿ç”¨ async generator è¿”å›æµå¼æ–‡æœ¬
 */
export async function* streamAIChat(
  messages: Array<{ role: 'user' | 'assistant' | 'system'; content: string }>,
  aiConfig: AIConfig
): AsyncGenerator<string, void, unknown> {
  try {
    // åˆ›å»º MCP æ’ä»¶ï¼ˆå†…ç½® fetch å·¥å…·ï¼‰
    const mcpPlugin = createMcpPlugin({
      verbose: false,
      toolPrefix: false
    })

    // åˆ›å»ºå·¥å…·è°ƒç”¨å¤„ç†æ’ä»¶
    const toolUsePlugin = createPromptToolUsePlugin({
      verbose: false
    })

    // åˆ›å»ºæ‰§è¡Œå™¨
    const executor = createExecutor(
      aiConfig.providerId,
      {
        apiKey: aiConfig.apiKey,
        ...(aiConfig.baseURL && { baseURL: aiConfig.baseURL })
      } as any,
      [mcpPlugin, toolUsePlugin] // æ·»åŠ æ’ä»¶ï¼šMCPå·¥å…· + å·¥å…·è°ƒç”¨å¤„ç†
    )

    // è°ƒç”¨æµå¼æ–‡æœ¬ç”Ÿæˆ
    const result = await executor.streamText({
      model: aiConfig.model,
      messages: messages.map(msg => ({
        role: msg.role,
        content: msg.content
      }))
    })

    // æµå¼è¿”å›æ–‡æœ¬
    for await (const chunk of result.textStream) {
      yield chunk
    }
  } catch (error) {
    console.error('âŒ Error in AI chat stream:', error)
    throw error
  }
}

/**
 * ç”Ÿæˆç®€å•çš„ AI å“åº”ï¼ˆéæµå¼ï¼‰
 */
export async function generateAIResponse(
  userMessage: string,
  aiConfig: AIConfig
): Promise<string> {
  try {
    // åˆ›å»º MCP æ’ä»¶ï¼ˆå†…ç½® fetch å·¥å…·ï¼‰
    const mcpPlugin = createMcpPlugin({
      verbose: false,
      toolPrefix: false
    })

    // åˆ›å»ºå·¥å…·è°ƒç”¨å¤„ç†æ’ä»¶
    const toolUsePlugin = createPromptToolUsePlugin({
      verbose: false
    })

    const executor = createExecutor(
      aiConfig.providerId,
      {
        apiKey: aiConfig.apiKey,
        ...(aiConfig.baseURL && { baseURL: aiConfig.baseURL })
      } as any,
      [mcpPlugin, toolUsePlugin]
    )

    const result = await executor.generateText({
      model: aiConfig.model,
      messages: [
        {
          role: 'user',
          content: userMessage
        }
      ]
    })

    return result.text
  } catch (error) {
    console.error('âŒ Error generating AI response:', error)
    throw error
  }
}
